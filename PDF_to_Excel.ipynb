{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bc6c6311-de8f-4c56-a4ad-e7e97ff75db4",
   "metadata": {},
   "source": [
    "# FXP capital account parsing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448e0cbd-387b-4b68-8965-db0b7cbd5242",
   "metadata": {},
   "source": [
    "#### Necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ca6e8c1-09cd-44f9-9b36-4a0b21d3efa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import camelot\n",
    "import pandas as pd\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da89b287-9fe5-48ec-86f8-cb781c9cccac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Source of PDFs\n",
    "pdf_dir = r\"C:\\Users\\ArtemPetrushin\\Servc\\FXP - General\\Financial Statements\\2025\\2025 Q2\\CA pdf\"\n",
    "\n",
    "# Results output\n",
    "output_dir = r\"C:\\Users\\ArtemPetrushin\\Desktop\\Pithon\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23073630-60a7-46b5-b321-d513fadb3289",
   "metadata": {},
   "source": [
    "#### Variables to store results of parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "070e0509-cdc1-4733-b7f6-1e4d4aec0fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List to store all the dataframes with balances from the body of the document. We'll concatenate them in the end\n",
    "all_tables = []\n",
    "\n",
    "# Dataframe with investors' name checks\n",
    "df_check_investors = pd.DataFrame(columns=['Investor ID in PDF file name',\n",
    "                                           'Investor ID in the document',\n",
    "                                           'Match',\n",
    "                                           'Investor name'])\n",
    "\n",
    "# Dataframe with balance checks\n",
    "df_check_results = pd.DataFrame(columns=['PDF file name',\n",
    "                                         'Balance lines #',\n",
    "                                         'Year-to-date',\n",
    "                                         'Inception-to-date',\n",
    "                                         'Difference'])\n",
    "\n",
    "# Dataframe with balance checks\n",
    "df_check_contribution = pd.DataFrame(columns=['PDF file name',\n",
    "                                         'Commitment',\n",
    "                                         'Contribution',\n",
    "                                         'Called',\n",
    "                                         'Contribution minus called',\n",
    "                                        'Uncalled',\n",
    "                                        'Commitment minus Contribution minus Uncalled'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "657defc0-ed25-42d6-a695-fe474c361f29",
   "metadata": {},
   "source": [
    "#### Common functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fab0a4e5-7b3c-4401-ab08-978a95566cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert numbers in financial format to numeric\n",
    "def convert_value(value):\n",
    "    \"\"\"\n",
    "    Convert financial format string into numeric:\n",
    "    1. Dash (-) → 0.0\n",
    "    2. (number) → negative number\n",
    "    3. number,number → number (deletes commas)\n",
    "    4. In other cases standard conversion to float\n",
    "    \"\"\"\n",
    "    # Replacing dash\n",
    "    if isinstance(value, str) and value.strip() == '-':\n",
    "        return 0.0\n",
    "\n",
    "    # NaN to float\n",
    "    if pd.isna(value):\n",
    "        return float('nan')  # returns Nan as a float\n",
    "\n",
    "    if isinstance(value, str):\n",
    "        value = value.strip()  # deletes spaces on both sides of the text\n",
    "\n",
    "        # Converting numbers in brackets including with commas\n",
    "        if re.fullmatch(r'\\([\\d,]+\\)', value):\n",
    "            num = value.replace(',', '').strip('()')\n",
    "            try:\n",
    "                return -float(num)\n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "        # Converting numbers with commas\n",
    "        elif re.fullmatch(r'[\\d,]+', value):\n",
    "            try:\n",
    "                return float(value.replace(',', ''))\n",
    "            except ValueError:\n",
    "                pass\n",
    "\n",
    "    # Trying to convert to float with a standard method\n",
    "    try:\n",
    "        return float(value)\n",
    "    except (ValueError, TypeError):\n",
    "        return float('nan')\n",
    "\n",
    "\n",
    "# Function to split one column in dataframe into two. It will be necessary to extract investor's name.\n",
    "def split_column_by_colon(df: pd.DataFrame, column_name: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Splits a specified DataFrame column into two new columns based on the \n",
    "    first occurrence of a colon.\n",
    "\n",
    "    This function creates two new columns named '{original_name}_key' and \n",
    "    '{original_name}_value'. Values in the new columns are stripped of any\n",
    "    leading or trailing whitespace. The original column is then dropped.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame to process.\n",
    "        column_name (str): The name of the column to be split.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: A new DataFrame with the specified column replaced by \n",
    "                      two new columns ('_key' and '_value').\n",
    "    \n",
    "    Raises:\n",
    "        KeyError: If a column with the specified name does not exist in the DataFrame.\n",
    "    \"\"\"\n",
    "    if column_name not in df.columns:\n",
    "        raise KeyError(f\"Column '{column_name}' not found in the DataFrame.\")\n",
    "\n",
    "    # Create a copy to avoid modifying the original DataFrame outside the function\n",
    "    df_copy = df.copy()\n",
    "\n",
    "    # 1. Split the column into two parts based on the first colon.\n",
    "    #    expand=True creates a new DataFrame from the split parts.\n",
    "    #    n=1 ensures the split happens only at the first occurrence of ':'\n",
    "    split_data = df_copy[column_name].str.split(':', n=1, expand=True)\n",
    "\n",
    "    # 2. Create names for the new columns\n",
    "    new_col_key = 100\n",
    "    new_col_value = 101\n",
    "    \n",
    "    # 3. Assign the split data to the new columns in our DataFrame.\n",
    "    #    Also, apply .str.strip() to remove any leading/trailing whitespace.\n",
    "    df_copy[new_col_key] = split_data[0].str.strip()\n",
    "    \n",
    "    # Handle the second column, which might contain None (or NaN) if no colon \n",
    "    # was found in the original string.\n",
    "    df_copy[new_col_value] = split_data[1].str.strip()\n",
    "\n",
    "    # 4. Drop the original column\n",
    "    df_copy = df_copy.drop(columns=[column_name])\n",
    "\n",
    "    return df_copy\n",
    "\n",
    "# Function to filter dataframe based on the firs and last rows' names.\n",
    "# It will be used to extract balance from the report and capital\n",
    "def filter_dataframe(df, first_row, last_row):\n",
    "    \"\"\"\n",
    "    Filters a DataFrame based on a start and end row value, \n",
    "    and returns an independent copy of the filtered data.\n",
    "    \"\"\"\n",
    "   \n",
    "    first_row = str(first_row)\n",
    "    last_row = str(last_row)    \n",
    "    \n",
    "    # Find the indices of the first and last rows\n",
    "    try:\n",
    "        start_idx = df[df[0] == first_row].index[0]\n",
    "        end_idx = df[df[0] == last_row].index[0]\n",
    "    except IndexError:\n",
    "        print(f\"Error: Could not find row '{first_row}' or '{last_row}'. Please check the data.\")\n",
    "        # Return an empty DataFrame with the same columns to avoid errors downstream\n",
    "        return pd.DataFrame(columns=df.columns)\n",
    "\n",
    "    print(\"start df: \", start_idx, \"end df: \", end_idx)\n",
    "\n",
    "    # Select the slice using .loc and IMMEDIATELY create a copy of it using .copy()\n",
    "    filtered_slice = df.loc[start_idx:end_idx]\n",
    "    \n",
    "    return filtered_slice.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d489e79a-e26b-4735-ad72-547bf0007e52",
   "metadata": {},
   "source": [
    "#### Extracting the main table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347cc2f1-d09d-437b-a73c-a55885f7a224",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pdf_file in os.listdir(pdf_dir):\n",
    "    pdf_path = os.path.join(pdf_dir, pdf_file)\n",
    "    print(f\"Processing file: {pdf_file}\")\n",
    "    # extracting file prefix to use in cycles below\n",
    "    file_prefix = os.path.splitext(pdf_file)[0]\n",
    "\n",
    "    try:\n",
    "        tables = camelot.read_pdf(pdf_path, \n",
    "                                  pages='1', \n",
    "                                  flavor='stream',\n",
    "                                 table_areas = ['80,590,580,300'])\n",
    "        \n",
    "        # Preview\n",
    "        if tables:            \n",
    "            # Получаем данные в виде DataFrame pandas\n",
    "            df_balance = tables[0].df\n",
    "            # print(\"Extracted balance:\")\n",
    "            # display(df_balance) # display() лучше отображает таблицы в Jupyter\n",
    "        else:\n",
    "            print(\"Tables in the area have not been found.\")\n",
    "\n",
    "        # Converting financial type of data into numeric format\n",
    "        df_balance.loc[:, 1] = df_balance[1].apply(convert_value)\n",
    "        df_balance.loc[:, 2] = df_balance[2].apply(convert_value)\n",
    "\n",
    "        # Uncomment to display PDF image\n",
    "        # display(df_balance)\n",
    "        \n",
    "        #Filtering a dataframe with extracted balance\n",
    "        df_filtered_balance = filter_dataframe(df_balance,\n",
    "                                               'Balance, beginning of period',\n",
    "                                               'Balance, end of period')\n",
    "        # #Filtering a dataframe with capital commitment\n",
    "        # df_filtered_capital_commitment = filter_dataframe(df_balance,\n",
    "        #                                        'Capital called',\n",
    "        #                                        'Uncalled capital commitment')\n",
    "    \n",
    "        # Convert values in columns 2 and 3 into numeric format\n",
    "        df_filtered_balance.loc[:, 1] = df_filtered_balance[1].apply(convert_value)\n",
    "        df_filtered_balance.loc[:, 2] = df_filtered_balance[2].apply(convert_value)\n",
    "    \n",
    "        # python calculated sum\n",
    "        col1_sum = df_filtered_balance[1][:-1].sum()\n",
    "        col2_sum = df_filtered_balance[2][:-1].sum()\n",
    "    \n",
    "        # the existing sum in the line \"Balance, end of period\"\n",
    "        col1_value = df_filtered_balance[1].iloc[-1]\n",
    "        col2_value = df_filtered_balance[2].iloc[-1]\n",
    "    \n",
    "        # Calculating the sum of given values and subtracting the calculated results\n",
    "        balance_check = col1_value + col2_value - col1_sum - col2_sum\n",
    "    \n",
    "        final_row = [balance_check, col1_sum, col2_sum]\n",
    "    \n",
    "        df_filtered_balance.loc[len(df_filtered_balance)+3] = final_row\n",
    "    \n",
    "        if balance_check != 0:\n",
    "            print (\"Check balances!\")\n",
    "    \n",
    "        # Rename columns: file name & column number\n",
    "        file_prefix = os.path.splitext(pdf_file)[0]  # exclude extension .pdf\n",
    "        df_filtered_balance.columns = [f\"{file_prefix}_col{i+1}\" for i in range(len(df_filtered_balance.columns))]\n",
    "    \n",
    "        # Making a list of all dataframes to save them after in one excel tab\n",
    "        all_tables.append(df_filtered_balance)\n",
    "\n",
    "        # Creating a row with checks results to save them after as a summary of checks\n",
    "        # It contains: name of the file, number of lines in the first column, year-to-date balance,\n",
    "        # inception-to-date balance, difference of the last two items\n",
    "        result_row = [file_prefix, df_filtered_balance.shape[0]-1,col1_sum,col2_sum,balance_check]\n",
    "        \n",
    "        # Appending the dataframe with summary of checks\n",
    "        # df_check_results.append(result_row)\n",
    "        df_check_results.loc[len(df_check_results)] = result_row\n",
    "\n",
    "        # print(df_balance.head(5))\n",
    "\n",
    "        # Commitment key words to extract information\n",
    "        keywords = ['Total capital commitment', 'Contribution', 'Capital called', 'Uncalled capital commitment']\n",
    "        \n",
    "        # Dictionary to store\n",
    "        extracted_values = {}\n",
    "        \n",
    "        keyword_col_index = 0\n",
    "        value_col_index = 2\n",
    "\n",
    "        # Cycle to go through keywords\n",
    "        for word in keywords:\n",
    "            try:\n",
    "                # Ищем строку, где значение в первой колонке (iloc[:, 0]) содержит искомое слово.\n",
    "                # .str.contains(word, na=False) - надежный способ поиска подстроки.\n",
    "                row = df_balance[df_balance.iloc[:, keyword_col_index].str.contains(word, na=False, case=False)]\n",
    "        \n",
    "                if not row.empty:\n",
    "                    # Если строка найдена, берем из нее значение из третьей колонки (iloc[:, 2])\n",
    "                    value = row.iloc[0, value_col_index]\n",
    "                    extracted_values[word] = value\n",
    "                    print(f\"Value of '{word}' is found: {value}\")\n",
    "                else:\n",
    "                     # Этот блок сработает, если слово не найдено\n",
    "                     print(f\"'{word}' has not been found in {keyword_col_index}.\")\n",
    "                     extracted_values[word] = None\n",
    "        \n",
    "            except IndexError:\n",
    "                # This error may raise if there are less than 3 columns in dataframe\n",
    "                print(f\"Index error: make sure the dataframe contains at least {value_col_index + 1} columns.\")\n",
    "                extracted_values[word] = None\n",
    "            except Exception as e:\n",
    "                # Other unexpected errors\n",
    "                print(f\"Unexpected error while searching for '{word}': {e}\")\n",
    "                extracted_values[word] = None\n",
    "\n",
    "        # Key words for search should match the key words above\n",
    "        total_commitment = extracted_values.get('Total capital commitment')\n",
    "        contribution_value = extracted_values.get('Contribution')    \n",
    "        called_value = extracted_values.get('Capital called')\n",
    "        uncalled_value = extracted_values.get('Uncalled capital commitment')\n",
    "        contribution_minus_called = contribution_value - called_value\n",
    "        final_check = total_commitment - called_value - uncalled_value\n",
    "\n",
    "        commitment_row = [file_prefix,\n",
    "                          total_commitment,\n",
    "                        contribution_value,\n",
    "                        called_value,\n",
    "                        contribution_minus_called,\n",
    "                        uncalled_value,\n",
    "                        final_check]\n",
    "    \n",
    "        df_check_contribution.loc[len(df_check_contribution)] = commitment_row\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error while processing {pdf_file}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8559b91-e3ab-491e-9600-c6a574232fab",
   "metadata": {},
   "source": [
    "#### Extracting investor's name and ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13980183-16db-4bb5-9175-49881f5e7d10",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pdf_file in os.listdir(pdf_dir):\n",
    "    pdf_path = os.path.join(pdf_dir, pdf_file)\n",
    "    print(f\"Processing file: {pdf_file}\")\n",
    "    # extracting file prefix to use in cycles below\n",
    "    file_prefix = os.path.splitext(pdf_file)[0]\n",
    "\n",
    "    try:\n",
    "        investor_tables = camelot.read_pdf(pdf_path, \n",
    "                                  pages='1', \n",
    "                                  flavor='stream',\n",
    "                                 table_areas = ['100,750,500,650'])\n",
    "        if investor_tables:\n",
    "            df_investor = investor_tables[0].df\n",
    "            # print(\"Extracted information on investor:\")\n",
    "            # print(df_investor)\n",
    "\n",
    "            df_investor_ID = split_column_by_colon(df_investor,0)\n",
    "            print()\n",
    "            print(df_investor_ID)\n",
    "            print()\n",
    "\n",
    "            # Collecting results of investors checks in 1 list to include in dataframe afterwards to export\n",
    "            # We compare 11 symbols in the file name to the value inside the document\n",
    "            investor_result_row = [\n",
    "                file_prefix[:11],\n",
    "                df_investor_ID.at[1,101],\n",
    "                file_prefix[:11] == df_investor_ID.at[1,101],\n",
    "                df_investor_ID.at[0, 101]\n",
    "            ]\n",
    "\n",
    "            # Inserting investor check in the dataframe\n",
    "            df_check_investors.loc[len(df_check_investors)] = investor_result_row\n",
    "            \n",
    "        else:\n",
    "            print(\"Info on investor has not been found in the specified area.\")\n",
    "            # Dataframe for the investor ID\n",
    "    except Exception as e:\n",
    "        print(f\"Error while parsing investor's name part of the document {pdf_file}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a246f2e-ea48-4821-afca-563504ba8485",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate dataframes into one\n",
    "merged_df = pd.concat(all_tables, axis=1)\n",
    "output_path = os.path.join(output_dir, \"FXP_merged_tables.xlsx\")\n",
    "\n",
    "# Check if the excel file we try to write exists already\n",
    "if not os.path.exists(output_path):\n",
    "    # Create a file with a sheet in it\n",
    "    with pd.ExcelWriter(output_path, engine=\"openpyxl\") as writer:\n",
    "        pd.DataFrame().to_excel(writer, sheet_name=\"Sheet\")\n",
    "\n",
    "with pd.ExcelWriter(output_path, engine=\"openpyxl\", mode=\"a\", if_sheet_exists=\"replace\") as writer:\n",
    "    merged_df.to_excel(writer, sheet_name=\"merged_tables\", index=False)\n",
    "    df_check_results.to_excel(writer, sheet_name=\"checks_summary\", index=False)\n",
    "    df_check_investors.to_excel(writer, sheet_name=\"checks_investors\", index=False)\n",
    "    df_check_contribution.to_excel(writer, sheet_name=\"contribution_check\", index=False)\n",
    "\n",
    "print(\"Result has been saved: \",output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1a4c75f-3c99-4b13-b44e-146ef1f24987",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
